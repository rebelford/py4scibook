{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6a5c74-d1d0-4192-8be3-e931b5669a7c",
   "metadata": {},
   "source": [
    "(module2-oop-data-structures/02-6-external-data-structures)=\n",
    "# 6. External Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bcc92-f59a-473b-ba7a-c03b7c9ce17a",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "## Content\n",
    "* Nature of NonVolatile Memory\n",
    "* Nature of Input/Output Operations\n",
    "* Understand Interfaces\n",
    "* Non-Volatile Data Structures\n",
    "\n",
    "| **Type**       | **Source Example** | **Data Format** | **Storage/Query Method** |\n",
    "|--------------|-----------------|--------------|-----------------|\n",
    "| File-Based Data | JSON, CSV, Pickle, HDF5 | Structured | File I/O (pandas, NumPy) |\n",
    "| Relational Databases | PubChem SQL, NOAA Climate Database | SQL (Structured) | Queries (SQL, Relational Model) |\n",
    "| NoSQL Databases | MongoDB, Firebase | JSON, BSON (Semi-Structured) | Queries (NoSQL, Document Store) |\n",
    "| APIs (REST) | PubChem API, OpenWeather API, NASA API | JSON, XML, CSV | RESTful Requests (`GET`, `POST`) |\n",
    "| SPARQL APIs (Linked Data) | Wikidata, PubChem RDF, DBpedia, Gene Ontology | RDF/XML, Turtle, SPARQL-JSON | SPARQL Queries (Graph-Based) |\n",
    "| Graph Databases (RDF Stores) | Blazegraph, Virtuoso, Neo4j (for Linked Data) | RDF, GraphML | Queries (SPARQL, Cypher) |\n",
    "| Web Scraping | Wikipedia, Research Articles, Google Scholar | HTML (Semi-Structured) | Parsing (BeautifulSoup, Scrapy) |\n",
    "| Streaming Data | EPA RSIG, IoT Sensor Networks | JSON, Avro, Protobuf | WebSockets, Kafka, MQTT |\n",
    "\n",
    "   \n",
    "\n",
    "## Process\n",
    "* I/O Operations\n",
    "   * Directory Hierarchies (read/write to specific locations) \n",
    "* Working with:\n",
    "   * `.txt` files\n",
    "   * `.csv` files\n",
    "   * `.json` files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7628f-f75a-4756-a7f0-6a37b20c65a0",
   "metadata": {},
   "source": [
    "# Introduction: Non-Volatile External Data Structures\n",
    "\n",
    "Python‚Äôs built-in data structures (lists, tuples, dictionaries, etc.) reside in volatile memory (RAM) and persist only as long as the Python interpreter is running. Once the interpreter exits, these structures are lost. In contrast, external data structures stored in non-volatile memory (such as files, databases, or serialized objects) persist beyond both the current Python session and hardware restarts, allowing data to be recovered even after the system reboots.\n",
    "\n",
    "1. **File-Based Data Structures**\n",
    "   - **Text-Based Files (Structured/Unstructured)**\n",
    "     - `.txt`: Raw text files (unstructured).\n",
    "     - `.csv`: Tabular data (structured, human-readable, but limited).\n",
    "     - `.json`: Key-value format (structured, hierarchical, readable).\n",
    "   - **Binary Files**\n",
    "     - `.pickle`: Stores Python objects in a serialized format (not human-readable).\n",
    "     - `.npy/.npz`: NumPy‚Äôs binary storage for efficient numerical data.\n",
    "\n",
    "2. **Databases (Structured, Queryable External Data)**\n",
    "   - **SQL Databases (Relational)**\n",
    "     - Store data in structured tables with defined relationships.\n",
    "     - Examples: SQLite, PostgreSQL, MySQL.\n",
    "   - **NoSQL Databases (Flexible, Key-Value, Document-Based)**\n",
    "     - Store unstructured or semi-structured data in key-value or document formats.\n",
    "     - Examples: MongoDB (documents), Redis (key-value pairs).\n",
    "\n",
    "3. **Web APIs and Networks as External Data Sources**\n",
    "   - Accessing data from remote servers (e.g., PubChem, weather services).\n",
    "   - Often return data in JSON, XML, or other standardized formats.\n",
    "   - Unlike local files or databases, APIs require a network connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59b42d-a58b-417f-ae52-9293e2430f8d",
   "metadata": {},
   "source": [
    "## Understanding Input/Output (I/O)\n",
    "\n",
    "At its core, **Input/Output (I/O)** refers to any communication between a program and the outside world. It is not limited to data storage and retrieval; it also includes interactions with users, hardware, and network resources. I/O operations can be broadly categorized into:\n",
    "\n",
    "1. **User Interaction**  \n",
    "   - Input: Receiving user input via `input()` or GUI elements.  \n",
    "   - Output: Displaying text via `print()`, rendering graphics, or updating a UI.\n",
    "\n",
    "2. **File I/O** (Non-volatile Storage)  \n",
    "   - Reading and writing data to files (e.g., `.txt`, `.csv`, `.json`, `.pickle`).\n",
    "   - Persistent storage that remains available after the program terminates.\n",
    "\n",
    "3. **Network I/O**  \n",
    "   - Communicating with remote servers, APIs, or databases over the internet.\n",
    "   - Sending and receiving data over sockets (e.g., accessing PubChem via an API).\n",
    "\n",
    "4. **Inter-process and Hardware I/O**  \n",
    "   - Communicating with external devices like sensors, databases, or microcontrollers.\n",
    "   - Data exchange between different programs or services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6a641-8ed4-43ba-9b9d-f6ce0b703555",
   "metadata": {},
   "source": [
    "## Understanding Interfaces\n",
    "Inherent in IO operations is the interface between two entities or systems and we are going to need to introduce the concept of an API (Application Program Interface).  If you look at the above IO systems you realize there are human, hardware and sofware components, and so there are different types of interfaces. The following table gives an overview of several interfaces, and as a human, you have used both CLIs and GUIs in this class.\n",
    "\n",
    "| **Interface Type** | **Example** | **Who/What Interacts?** |\n",
    "|-------------------|------------|-------------------|\n",
    "| **Graphical User Interface (GUI)** | Windows, Web Apps | **User ‚Üî System** (via visual elements like buttons, menus) |\n",
    "| **Command Line Interface (CLI)** | Terminal, Bash, Python REPL | **User ‚Üî System** (via text commands) |\n",
    "| **Application Programming Interface (API)** | REST API, Database API | **Software ‚Üî Software** (via structured requests & responses) |\n",
    "| **Hardware Interfaces** | USB, HDMI, Bluetooth | **Physical Devices ‚Üî System** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77dfd8-598a-472a-b78b-8498681b2d27",
   "metadata": {},
   "source": [
    "\n",
    "# 1. File Based Data Structures\n",
    "Before we proceed, we are going to install two new third party packages; Seaborn and pandas.  Seaborn is a visualization package built on Matplotlib and it comes with a series of files we can use for various data explorations.  Pandas is a data manipulation package built on Numpy and is widely used to handle structured data like csv, json, SQL, Excel...)\n",
    "\n",
    "## Text Files vs. Binary Files\n",
    "| Feature | Text Files | Binary Files |\n",
    "|---------|-----------|-------------|\n",
    "| **Storage Format** | Human-readable characters | Machine-readable bytes |\n",
    "| **Encoding** | Requires a character encoding (e.g., UTF-8) | Stored as raw data |\n",
    "| **Editing** | Can be edited with a simple text editor | Requires specialized software |\n",
    "| **Examples** | `.txt`, `.csv`, `.json`, `.xml` | `.exe`, `.jpg`, `.png`, `.dat` |\n",
    "\n",
    "\n",
    "### Comparing CSV, JSON, and Pickle\n",
    "\n",
    "| Feature        | **CSV (Comma-Separated Values) üìù** | **JSON (JavaScript Object Notation) üåê** | **Pickle (Python Object Serialization) ü•í** |\n",
    "|---------------|------------------------------------|-------------------------------------------|----------------------------------------------|\n",
    "| **Human-readable?** | ‚úÖ Yes (text-based, tabular format) | ‚úÖ Yes (nested, structured format) | ‚ùå No (binary format) |\n",
    "| **Supports structured data?** | ‚ùå No (flat, lacks hierarchy) | ‚úÖ Yes (nested, supports dictionaries/lists) | ‚úÖ Yes (fully supports Python objects) |\n",
    "| **Supports non-string data?** | ‚ùå No (everything is a string) | ‚úÖ Yes (numbers, lists, dicts) | ‚úÖ Yes (numbers, lists, dicts, tuples, objects) |\n",
    "| **Portable across languages?** | ‚úÖ Yes (universal) | ‚úÖ Yes (used in APIs, databases) | ‚ùå No (Python-specific) |\n",
    "| **Best used for?** | Storing **tabular** data (like spreadsheets) | Storing **hierarchical, structured** data | Saving **entire Python objects** for fast reloading |\n",
    "| **Ideal for?** | Data exchange (Excel, databases) | Config files, APIs, web apps | Machine learning models, Pandas DataFrames |\n",
    "\n",
    "### File Access Modes in Python\n",
    "Note, you place a b in front of the mode to run these for binary files, but we will not be modifying binary files, and will be using these with text files.\n",
    "\n",
    "| Mode | Meaning | Behavior |\n",
    "|------|---------|----------|\n",
    "| `'r'`  | Read mode | Opens a file for reading (default). File must exist. |\n",
    "| `'w'`  | Write mode | Opens a file for writing. If the file exists, it is erased! |\n",
    "| `'a'`  | Append mode | Opens a file for writing, but does **not** erase existing content. |\n",
    "| `'x'`  | Exclusive creation | Creates a new file. Fails if the file already exists. |\n",
    "| `'r+'` | Read + Write | Opens a file for both reading and writing. File must exist. |\n",
    "| `'w+'` | Write + Read | Opens a file for both, but **erases** the file first. |\n",
    "| `'a+'` | Append + Read | Opens a file for reading and writing, preserving content. |\n",
    "\n",
    "##  Text Formats\n",
    "A text file contains human-readable characters encoded using a standard like UTF-8 or ASCII. This can be contrasted to binary files that store data in machine-readable formats that can not be read by a human.  Examples of binary files jpeg images files, many types of instrumental data files, and a special way of preserving python in the forms of pickle files. Most of our data files  will be in text based formats as we want the data to be human readable.\n",
    "\n",
    "### Directory Hierarchy for Read/Writing Files\n",
    "When your read (input) or write (output) a file the default location is the directory you are running the script from. This means files can be stored all over the place, and we are going to create a directory hierarchy to organize our files as we read and write them. The Structure we are going to use will be programmatically generated in the next several scripts, and at the end of this module we will have four folders in our user directory that we are using in this class. The miniconda3 and projects directories we created in the first lesson, and two new directories for files, one being for our data and the other being a sandbox to play in. We will develop variables for the file_paths that will make it easy to read and write to these locations, no matter where our program is located.\n",
    "\n",
    "```text\n",
    "/home/user/\n",
    "    ‚îú‚îÄ‚îÄ data/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ project_a/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ project_b/\n",
    "    ‚îî‚îÄ‚îÄ sandbox/\n",
    "    ‚îî‚îÄ‚îÄ minconda3/\n",
    "    ‚îî‚îÄ‚îÄ projects/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ py4sci/ (.git repo)\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ other_project/ (.git repo)\n",
    "```\n",
    "\n",
    "There is another reason we are doing this, and that is because I am pushing the class files from my py4sci git repository to github, and I want the project files outside of the git repository as I do not want to fill up my repository with a bunch of data files. If you wish to push data files to the github, then you will need to make another data folder within your git repository.\n",
    "## *.txt Files\n",
    "If we want to read a file in the current working directory we would simply use\n",
    "```python\n",
    "with open(\"example.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "```\n",
    "But that code would throw an error as the file does not exist.\n",
    "\n",
    "In the following activity we are first going to check our home/user/ directory (~/) to see if the folder `sandbox` exists and if there is a file in it called `chemical_safety_log.txt`.  If it does not exist we will create it. Throughout this class I will be using two folders to write files to, my sandbox and my data folders. These folders are outside of the class git directory and so the files in them will not be pushed to github, and these repesent files I want you to create and not clone or pull from github.\n",
    "\n",
    "### Create .txt File in a Sandbox Directory\n",
    "Lets look at the following script before running it.\n",
    "\n",
    "```python\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "sb_file_path = os.path.join(sandbox_dir, \"chemical_safety_log.txt\")\n",
    "```\n",
    "`os.path.expanduser(\"~\")` expands the tilda to the full path (`/home/username`), by using os.path this will also work on Windows, Mac and Linux systems.\n",
    "\n",
    "`sandbox_dir = os.path.expanduser(\"~/sandbox/\")` assigns sandbox_dir to the full path `home/username/sandbox`\n",
    "\n",
    "`os.path.join(sandbox_dir, \"chemical_safety_log.txt\")` concatenates the file name to the path\n",
    "'sb_file_path = os.path.join(sandbox_dir, \"chemical_safety_log.txt\")' assigns the variable sb_file_path to the full path of the file in the sandbox (sb) directory.\n",
    "\n",
    "NOTE: This script will adjust to different users and operating systems, and so should work without modification for anyone who downloads the script from github.\n",
    "\n",
    "```python\n",
    "os.makedirs(sandbox_dir, exist_ok=True)\n",
    "```\n",
    "\n",
    "This script makes the directory assigned by the path of sandbox_dir on the users computer if it does not exist, with the `exist_od=True` preventing an error if the directory already exists\n",
    "\n",
    "```python\n",
    "if not os.path.exists(sb_file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Chemical Safety Log\\n\")\n",
    "        file.write(\"=\"*30 + \"\\n\")\n",
    "        file.write(\"Date: 2025-02-13\\n\")\n",
    "        file.write(\"Chemical: Acetone\\n\")\n",
    "        file.write(\"Incident: Small spill in lab. Cleaned with absorbent pads.\\n\")\n",
    "        file.write(\"Preventive Action: Ensure lid is tightly sealed after use.\\n\\n\")\n",
    "    print(\"Initial Safety Log created\")\n",
    "```\n",
    "Normally an if statement runs the block of code if it is true, but here we are using a Boolean `not` to negate the condition. So if the path defined by the variable `file_path` does NOT exist, the block of code is executed, and the block is skipped if the path location exist.  So if the file chemical_safety_log.txt exists in the directory /~/sandbox/ the code is skipped, and otherwise the file is created and the data with incident is written to the file.\n",
    "\n",
    "The final block of code reads the file defined by the variable file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18378726-a7bc-4f29-a9a0-6f97bc5b25ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Contents:\n",
      "\n",
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file path in ~/sandbox/\n",
    "# Assign to variable chem_safety_log_sbpath (chemical safety log sandbox path)\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "chem_safety_log_sbpath = os.path.join(sandbox_dir, \"chemical_safety_log.txt\")\n",
    "\n",
    "# Ensure the ~/sandbox/ directory exists\n",
    "os.makedirs(sandbox_dir, exist_ok=True)\n",
    "\n",
    "# Create the file if it does not exist\n",
    "if not os.path.exists(chem_safety_log_sbpath):\n",
    "    with open(chem_safety_log_sbpath, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Chemical Safety Log\\n\")\n",
    "        file.write(\"=\"*30 + \"\\n\")\n",
    "        file.write(\"Date: 2025-02-13\\n\")\n",
    "        file.write(\"Chemical: Acetone\\n\")\n",
    "        file.write(\"Incident: Small spill in lab. Cleaned with absorbent pads.\\n\")\n",
    "        file.write(\"Preventive Action: Ensure lid is tightly sealed after use.\\n\\n\")\n",
    "    print(\"Initial Safety Log created\")\n",
    "\n",
    "# Now, read the file safely\n",
    "with open(chem_safety_log_sbpath, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(\"File Contents:\\n\")\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8de15-ce0d-4f94-8d98-8c3b8f479345",
   "metadata": {},
   "source": [
    "The above code did several things.\n",
    "1. Created directory sandbox if it did not exist\n",
    "2. Created file chemical_safety_log.txt if it did not exist\n",
    "3. created a global variable chem_safety_log_sbpath that represents the path to the chemical_safety_log.txt file in the sandbox and can be used by other scripts during this python session.\n",
    "\n",
    "Open the **File Browser** in Jupyter Lab and navigate to the new folder and verify that the file chemical_safety_log.txt has been created. You can double click it to open it as a textfile in the jupyter lab interface.\n",
    "\n",
    "**Note**, in the jupyter lab the following does not work: \n",
    "```python\n",
    "with open(\"~/sandbox/chemical_safety_log.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "```\n",
    "(Run the next code cell and you get an error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e002fe2-705d-443d-bdf2-6a682e8cba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.expanduser(\"~/sandbox/chemical_safety_log.txt\")\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a626d-841a-4dc4-ad61-ecaef9150915",
   "metadata": {},
   "source": [
    "**What is going on?** It is clear that the directory and file exist, and the issue is that Python does not automatically expand `~` to the home directory when inside of `open()`. There are two solutions.  \n",
    "   1. Use the full path '/home/rebelford/sandbox/chemical_safety_log.txt'\n",
    "   2. Use the global variable file_path for the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1781bfe8-7542-4bb3-a3bc-d5f2bc3437b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 1, be sure to replace rebelford with your username\n",
    "with open(\"/home/rebelford/sandbox/chemical_safety_log.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07457cc6-dfcb-4ca4-a443-df5daa320470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(chem_safety_log_sbpath, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db56d65-29f9-4345-895f-6ecdbc971b52",
   "metadata": {},
   "source": [
    "**RESTART KERNEL and Clear All Output**\n",
    "Now run the next code cell, and it fails, even though it just worked, and this is because you have not defined the variable file_path, which exists in memory and was lost when you restarted the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b84975-fc9e-4d9f-ba3f-7a0196fe83e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(chem_safety_log_sbpath, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8493acd-18cb-46c5-8735-aedc7392b264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "chem_safety_log_sbpath = os.path.expanduser(\"~/sandbox/chemical_safety_log.txt\")  # Expands '~' to full path\n",
    "\n",
    "with open(chem_safety_log_sbpath, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38424cc-643e-4901-8b4a-8ad0c0c7a93c",
   "metadata": {},
   "source": [
    "**Quick Review:** We are using the variable **chem_safety_log_sbpath** so that we can direct our scripts to the file we generated in the sandbox. If we did not do this we would clutter our working directory with files. It is a best practice to organize where you read and write to and you can always change file_path to the actual path, or simply the file name if it is in the current working directory (the directory the notebook you are running resides in).\n",
    "## Appending a File\n",
    "We need to add a new incident to our accident log, and do so by **changing the Python file access code from 'w' to 'a'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ceaf64-28b0-4733-89e2-90f5ed42d7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New entry added to safety log.\n"
     ]
    }
   ],
   "source": [
    "# Appending a new safety log entry\n",
    "# Note, we are using the variable chem_safety_log_sbpath instead of the path to the file\n",
    "with open(chem_safety_log_sbpath, \"a\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"Date: 2025-02-14\\n\")\n",
    "    file.write(\"Chemical: Hydrochloric Acid (HCl)\\n\")\n",
    "    file.write(\"Incident: Minor exposure on gloves. No injury.\\n\")\n",
    "    file.write(\"Preventive Action: Double-check gloves for leaks before use.\\n\\n\")\n",
    "\n",
    "print(\"New entry added to safety log.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b146b92a-78fc-4994-a68a-076541eeaca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Safety Log\n",
      "==============================\n",
      "Date: 2025-02-13\n",
      "Chemical: Acetone\n",
      "Incident: Small spill in lab. Cleaned with absorbent pads.\n",
      "Preventive Action: Ensure lid is tightly sealed after use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "Date: 2025-02-14\n",
      "Chemical: Hydrochloric Acid (HCl)\n",
      "Incident: Minor exposure on gloves. No injury.\n",
      "Preventive Action: Double-check gloves for leaks before use.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the file using the predefined variable\n",
    "with open(chem_safety_log_sbpath, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a7ce6-9f65-41ca-ac5f-871415484eba",
   "metadata": {},
   "source": [
    "# Best Practices\n",
    "1. Use the `with` statement to ensure the file is properly closed:\n",
    "   ```python\n",
    "   with open('datasets_and_images_2022/namd/namd_subset.csv', 'r', encoding='utf-8') as file:\n",
    "       content = file.read()\n",
    "   ```\n",
    "\n",
    "2. Specify the encoding explicitly to avoid potential issues with different systems:\n",
    "   ```python\n",
    "   with open('datasets_and_images_2022/namd/namd_subset.csv', 'r', encoding='utf-8') as file:\n",
    "       content = file.read()\n",
    "   ```\n",
    "\n",
    "3. Use appropriate mode for your needs. For reading a CSV file, 'r' is sufficient.\n",
    "\n",
    "4. Handle potential exceptions, especially `FileNotFoundError`:\n",
    "   ```python\n",
    "   try:\n",
    "       with open('datasets_and_images_2022/namd/namd_subset.csv', 'r', encoding='utf-8') as file:\n",
    "           content = file.read()\n",
    "   except FileNotFoundError:\n",
    "       print(\"The file was not found.\")\n",
    "   ```\n",
    "## Adhoc Convention for Naming File Paths\n",
    "The file path needs to define two things, the path and the file, and so we are going to use a two part convention name-directory name-path, that way you know what file and path a path variable goes to.  If we wanted to put a spectral file called uv_vis1 in the data directory a good name would be 'uv_vis1_datapath', and the following script could create it:\n",
    "```python\n",
    "data_dir = os.path.expanduser(\"~/data/\")\n",
    "uv_vis1_datapath = os.path.join(data_dir, \"uv_vis1.csv\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107047b-5134-4f8e-8cfd-0ea4eb147cf4",
   "metadata": {},
   "source": [
    "# CSV (Comma-Separated Values)\n",
    "CSV files store **tabular data** (rows and columns) in a plain-text format, where values are separated by commas. It is one of the **simplest and most widely used** file formats for data exchange\n",
    "- Best for **flat, table-like data** (rows and columns).\n",
    "- Lacks structure: everything is a **string**, requiring **manual conversions** (e.g., numbers remain strings).\n",
    "- Easy to share, but **loses relationships between data** (e.g., nested structures are hard to represent).\n",
    "\n",
    "## csv module (built-in)\n",
    "Python has a built-in CSV (Comma Separated Variables) module that we will use for working with CSV files.  Later we will use features of Pandas, but right now we want to stick to built-in python features.\n",
    "\n",
    "| Method/Function/Object | Description |\n",
    "|------------------------|-------------|\n",
    "| `csv.reader()` | Creates a reader object for reading CSV data |\n",
    "| `csv.writer()` | Creates a writer object for writing CSV data |\n",
    "| `csv.DictReader()` | Creates a dictionary-based reader object |\n",
    "| `csv.DictWriter()` | Creates a dictionary-based writer object |\n",
    "| `csv.Dialect` | Base class for defining CSV dialects |\n",
    "| `csv.register_dialect()` | Registers a custom CSV dialect |\n",
    "| `csv.get_dialect()` | Retrieves a registered dialect |\n",
    "| `csv.list_dialects()` | Lists all registered dialects |\n",
    "| `csv.field_size_limit()` | Sets the maximum field size |\n",
    "\n",
    "## CSV Activity - Create a Dictionary of Halogen Properties\n",
    "We ill use an activity to learn how to work with csv files and the csv module. In this activity we will convert a CSV file into a python dictionary of dictionaries for the halogens, where the keys are the element symbols, and the values is a dictionary of that element, which has keys of elemental properties and values of the values of those properties\n",
    "### Overview\n",
    "1. Generate a csv file\n",
    "2. Read the CSV file\n",
    "4. Convert to a list of lists\n",
    "5. Separate the Headers (keys) from the data (values)\n",
    "6. Use csvdict to convert each row to a dictionary\n",
    "\n",
    "### 1. Create CSV file from list of tuples\n",
    "#### csv.writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a79bea5-2677-452a-b348-bfab007d13d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('F', 9, 18.998, 3.98), ('Cl', 17, 35.45, 3.16), ('Br', 35, 79.904, 2.96), ('I', 53, 126.9, 2.66), ('At', 85, 210, 2.2), ('Ts', 117, 294, None)]\n",
      "CSV file created successfully at: /home/rebelford/sandbox/halogens.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define file path in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_csv_sbpath = os.path.join(sandbox_dir, \"halogens.csv\")\n",
    "\n",
    "# Data lists\n",
    "halogens = ['F', 'Cl', 'Br', 'I', 'At', 'Ts']\n",
    "atomic_numbers = [9, 17, 35, 53, 85, 117]\n",
    "atomic_masses = [18.998, 35.45, 79.904, 126.9, 210, 294]\n",
    "electronegativities = [3.98, 3.16, 2.96, 2.66, 2.2, None]\n",
    "\n",
    "# Combine into rows\n",
    "data = list(zip(halogens, atomic_numbers, atomic_masses, electronegativities))  # Convert to list to avoid exhaustion\n",
    "print(data)  # Debugging: Check if data is structured correctly\n",
    "\n",
    "# Write to CSV file\n",
    "with open(halogen_csv_sbpath, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Element\", \"Atomic Number\", \"Atomic Mass\", \"Electronegativity\"])  # Header\n",
    "    writer.writerows(data)  # Data rows\n",
    "\n",
    "print(f\"CSV file created successfully at: {halogen_csv_sbpath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b5a4e-451e-43d5-9b43-8e62f5737030",
   "metadata": {},
   "source": [
    "## 2. Read csv file\n",
    "**restart your kernel and clear all output**\n",
    "### csv.reader()\n",
    "\n",
    "### print each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a593a112-bbab-4258-b886-6c0bf4d5e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Element', 'Atomic Number', 'Atomic Mass', 'Electronegativity']\n",
      "['F', '9', '18.998', '3.98']\n",
      "['Cl', '17', '35.45', '3.16']\n",
      "['Br', '35', '79.904', '2.96']\n",
      "['I', '53', '126.9', '2.66']\n",
      "['At', '85', '210', '2.2']\n",
      "['Ts', '117', '294', '']\n",
      "<class '_csv.reader'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define file path in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_csv_sbpath = os.path.join(sandbox_dir, \"halogens.csv\")\n",
    "\n",
    "with open(halogen_csv_sbpath, mode=\"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        print(row)  # Each row is a list\n",
    "print(type(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ce6ed-bda0-49ba-b02c-29eb070304fe",
   "metadata": {},
   "source": [
    "### Create a list of lists representing the csv file\n",
    "Now that we have created a csv object we can convert it to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c545116d-04f4-4f17-b9dc-e3715fb31c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Element', 'Atomic Number', 'Atomic Mass', 'Electronegativity'], ['F', '9', '18.998', '3.98'], ['Cl', '17', '35.45', '3.16'], ['Br', '35', '79.904', '2.96'], ['I', '53', '126.9', '2.66'], ['At', '85', '210', '2.2'], ['Ts', '117', '294', '']]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open(halogen_csv_sbpath, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    halogens_data = list(reader)\n",
    "\n",
    "# Display the data\n",
    "\n",
    "print(halogens_data)\n",
    "print(type(halogens_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbeb416-c17f-4488-9927-4107ea97af6e",
   "metadata": {},
   "source": [
    "### Create lists for keys and values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906c9a9b-efe2-44ab-a310-f3cae8df01bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Element', 'Atomic Number', 'Atomic Mass', 'Electronegativity'] \n",
      "\n",
      "[['F', '9', '18.998', '3.98'], ['Cl', '17', '35.45', '3.16'], ['Br', '35', '79.904', '2.96'], ['I', '53', '126.9', '2.66'], ['At', '85', '210', '2.2'], ['Ts', '117', '294', '']]\n"
     ]
    }
   ],
   "source": [
    "with open(halogen_csv_sbpath, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # Reads the first row (header)\n",
    "    halogens_data = list(reader)  # Reads the remaining rows\n",
    "print(header,'\\n')    \n",
    "print(halogens_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1741d6-1797-4069-972f-299b8277af83",
   "metadata": {},
   "source": [
    "## 3. Convert Each Row to a Dictionary\n",
    "### csv.DictReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76efe002-c571-4d7f-9de9-88939623cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Element': 'F', 'Atomic Number': '9', 'Atomic Mass': '18.998', 'Electronegativity': '3.98'}\n",
      "{'Element': 'Cl', 'Atomic Number': '17', 'Atomic Mass': '35.45', 'Electronegativity': '3.16'}\n",
      "{'Element': 'Br', 'Atomic Number': '35', 'Atomic Mass': '79.904', 'Electronegativity': '2.96'}\n",
      "{'Element': 'I', 'Atomic Number': '53', 'Atomic Mass': '126.9', 'Electronegativity': '2.66'}\n",
      "{'Element': 'At', 'Atomic Number': '85', 'Atomic Mass': '210', 'Electronegativity': '2.2'}\n",
      "{'Element': 'Ts', 'Atomic Number': '117', 'Atomic Mass': '294', 'Electronegativity': ''}\n"
     ]
    }
   ],
   "source": [
    "with open(halogen_csv_sbpath, mode=\"r\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        print(row)  # Each row is a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb43ac-39ed-4e78-8ec8-485415c7d0bc",
   "metadata": {},
   "source": [
    "## 4. Create Single Key Dictionary of Dictionaries for each Halogen with symbols as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831a8170-2b0a-424d-bf2e-02b791d1bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: {'Atomic Number': '9', 'Atomic Mass': '18.998', 'Electronegativity': '3.98'}\n",
      "Cl: {'Atomic Number': '17', 'Atomic Mass': '35.45', 'Electronegativity': '3.16'}\n",
      "Br: {'Atomic Number': '35', 'Atomic Mass': '79.904', 'Electronegativity': '2.96'}\n",
      "I: {'Atomic Number': '53', 'Atomic Mass': '126.9', 'Electronegativity': '2.66'}\n",
      "At: {'Atomic Number': '85', 'Atomic Mass': '210', 'Electronegativity': '2.2'}\n",
      "Ts: {'Atomic Number': '117', 'Atomic Mass': '294', 'Electronegativity': ''}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Initialize an empty dictionary to store each halogen's data\n",
    "halogens_dict = {}\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open(halogen_csv_sbpath, mode=\"r\", newline=\"\") as file:\n",
    "    # Create a DictReader with specified field names\n",
    "    reader = csv.DictReader(file, fieldnames=[\"symbol\", \"Atomic Number\", \"Atomic Mass\", \"Electronegativity\"])\n",
    "    next(reader)  # Skip the header row if it exists\n",
    "    for row in reader:\n",
    "        # Use the symbol as the key and store the rest of the data as a dictionary\n",
    "        symbol = row.pop(\"symbol\")\n",
    "        halogens_dict[symbol] = row\n",
    "\n",
    "# Display the data\n",
    "for symbol, data in halogens_dict.items():\n",
    "    print(f\"{symbol}: {data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e65edfc-f5af-428a-a66c-1de5a7d0561b",
   "metadata": {},
   "source": [
    "## 5. Combine into a Dictionary of Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b7e6cd-4d01-43b3-bdc7-50b46627baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': {'Atomic Number': '9', 'Atomic Mass': '18.998', 'Electronegativity': '3.98'}, 'Cl': {'Atomic Number': '17', 'Atomic Mass': '35.45', 'Electronegativity': '3.16'}, 'Br': {'Atomic Number': '35', 'Atomic Mass': '79.904', 'Electronegativity': '2.96'}, 'I': {'Atomic Number': '53', 'Atomic Mass': '126.9', 'Electronegativity': '2.66'}, 'At': {'Atomic Number': '85', 'Atomic Mass': '210', 'Electronegativity': '2.2'}, 'Ts': {'Atomic Number': '117', 'Atomic Mass': '294', 'Electronegativity': ''}}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# create empty dictionary\n",
    "halogen_dict = {}\n",
    "\n",
    "with open(halogen_csv_sbpath, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        symbol = row.pop(\"Element\")  # Extract the symbol and remove it from the row dictionary\n",
    "        halogen_dict[symbol] = row   # Assign the remaining data to the symbol key\n",
    "\n",
    "print(halogen_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1cd1965-efb1-417b-b1d9-de4e2283b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The atomic mass of Iodine is 126.9 amu.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The atomic mass of Iodine is {halogen_dict['I']['Atomic Mass']} amu.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093739-8ca2-44d1-a7c5-e8e2f5be5b92",
   "metadata": {},
   "source": [
    "In the next activity we will convert a halogen dictionary of dictionaries to a json file that will allow us to store a functioning dictionary of halogen properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ef2e3-2a1f-473c-b7df-e8a54c0bfdc2",
   "metadata": {},
   "source": [
    "# JSON (JavaScript Object Notation)\n",
    "- Supports dictionaries, lists, numbers, and strings.\n",
    "- Maintains data structure (nested objects, hierarchy).\n",
    "- Works across different languages (Python, JavaScript, C, etc.).\n",
    "- **Slight limitation**: It doesn‚Äôt support Python-specific objects like `tuples` and `sets`.\n",
    "  \n",
    "## JSON Structure\n",
    "```json\n",
    "{\n",
    "  \"chemicals\": [\n",
    "    {\"name\": \"Water\", \"melting_point\": 0, \"boiling_point\": 100},\n",
    "    {\"name\": \"Ethanol\", \"melting_point\": -114, \"boiling_point\": 78},\n",
    "    {\"name\": \"Acetone\", \"melting_point\": -95, \"boiling_point\": 56}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "- Uses **key-value pairs**.\n",
    "- Supports **hierarchical data** (nested dictionaries and lists).\n",
    "- **More flexible** than CSV.\n",
    "\n",
    "## jason module (built-in)\n",
    "\n",
    "| Method/Function | Description |\n",
    "|-----------------|-------------|\n",
    "| `json.dumps()` | Serialize Python object to a JSON formatted string |\n",
    "| `json.loads()` | Deserialize JSON string to a Python object |\n",
    "| `json.dump()` | Serialize Python object to a JSON formatted stream (file) |\n",
    "| `json.load()` | Deserialize JSON formatted stream (file) to a Python object |\n",
    "| `json.JSONEncoder` | Base class for custom JSON encoders |\n",
    "| `json.JSONDecoder` | Base class for custom JSON decoders |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Writing to a json file\n",
    "halogen_dict\n",
    "```python\n",
    "import json\n",
    "\n",
    "with open(\"chemical_safety.json\", \"w\") as file:\n",
    "    json.dump(chemical_safety_data, file, indent=4)\n",
    "\n",
    "print(\"Data saved to chemical_safety.json\")\n",
    "```\n",
    "The following code reads the csv file we made earlier and converts it to a json file\n",
    "### Reading a json file\n",
    "```python\n",
    "with open(\"chemical_safety_log\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    print(data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972e5b3-1765-4fd6-996d-059dbe427f74",
   "metadata": {},
   "source": [
    "## JSON Activity\n",
    "In this activity we will:\n",
    "  1. Convert the halogen.csv file to a dictionary\n",
    "  2. Save the dictionary as a json file\n",
    "  3. Open the json file as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "992939b3-b9c4-4868-a896-89de9300ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fluorine': {'symbol': 'F', 'atomic_number': 9, 'atomic_mass': 18.998, 'electronegativity': 3.98}, 'Chlorine': {'symbol': 'Cl', 'atomic_number': 17, 'atomic_mass': 35.45, 'electronegativity': 3.16}, 'Bromine': {'symbol': 'Br', 'atomic_number': 35, 'atomic_mass': 79.904, 'electronegativity': 2.96}, 'Iodine': {'symbol': 'I', 'atomic_number': 53, 'atomic_mass': 126.9, 'electronegativity': 2.66}, 'Astatine': {'symbol': 'At', 'atomic_number': 85, 'atomic_mass': 210.0, 'electronegativity': 2.2}, 'Tennessine': {'symbol': 'Ts', 'atomic_number': 117, 'atomic_mass': 294.0, 'electronegativity': None}}\n",
      "JSON file '/home/rebelford/sandbox/halogens.json' has been created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "# Define file path in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_csv_sbpath = os.path.join(sandbox_dir, \"halogens.csv\")\n",
    "halogen_json_sbpath = os.path.join(sandbox_dir, \"halogens.json\")\n",
    "\n",
    "# Halogen name mappings (to match symbol to full element name)\n",
    "halogen_names = {\n",
    "    \"F\": \"Fluorine\",\n",
    "    \"Cl\": \"Chlorine\",\n",
    "    \"Br\": \"Bromine\",\n",
    "    \"I\": \"Iodine\",\n",
    "    \"At\": \"Astatine\",\n",
    "    \"Ts\": \"Tennessine\"\n",
    "}\n",
    "\n",
    "# Read CSV and convert to a dictionary of dictionaries\n",
    "halogen_data = {}\n",
    "with open(halogen_csv_sbpath, mode=\"r\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file, delimiter=\",\")  # Use ',' if comma-separated\n",
    "    for row in reader:\n",
    "        element_name = halogen_names[row[\"Element\"]]  # Convert symbol to full name\n",
    "        halogen_data[element_name] = {\n",
    "            \"symbol\": row[\"Element\"],  # Include symbol inside the dictionary\n",
    "            \"atomic_number\": int(row[\"Atomic Number\"]),\n",
    "            \"atomic_mass\": float(row[\"Atomic Mass\"]),\n",
    "            \"electronegativity\": float(row[\"Electronegativity\"]) if row[\"Electronegativity\"] else None\n",
    "        }\n",
    "print(halogen_data)\n",
    "# Write to JSON\n",
    "with open(halogen_json_sbpath, mode=\"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(halogen_data, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON file '{halogen_json_sbpath}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5a7d0-838e-4383-a355-85b01a7df673",
   "metadata": {},
   "source": [
    "**Important** Note that the data in a **csv file is all strings**, and when we created the csv file we converted it the atomic numbers to integers, and the atomic mass and electronegativty to floats\n",
    "\n",
    "Now that you have created the json file, **restart the kernel and clear output of all cells**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5013d169-d246-4197-bc30-be7e800e88ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fluorine': {'symbol': 'F', 'atomic_number': 9, 'atomic_mass': 18.998, 'electronegativity': 3.98}, 'Chlorine': {'symbol': 'Cl', 'atomic_number': 17, 'atomic_mass': 35.45, 'electronegativity': 3.16}, 'Bromine': {'symbol': 'Br', 'atomic_number': 35, 'atomic_mass': 79.904, 'electronegativity': 2.96}, 'Iodine': {'symbol': 'I', 'atomic_number': 53, 'atomic_mass': 126.9, 'electronegativity': 2.66}, 'Astatine': {'symbol': 'At', 'atomic_number': 85, 'atomic_mass': 210.0, 'electronegativity': 2.2}, 'Tennessine': {'symbol': 'Ts', 'atomic_number': 117, 'atomic_mass': 294.0, 'electronegativity': None}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# Define file path in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_json_sbpath = os.path.join(sandbox_dir, \"halogens.json\")\n",
    "\n",
    "with open(halogen_json_sbpath, \"r\") as file:\n",
    "    halogen_dict = json.load(file)\n",
    "    print(halogen_dict,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c67f0b9-dcf9-4cd4-a4c7-cca3a3b593b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Fluorine', 'Chlorine', 'Bromine', 'Iodine', 'Astatine', 'Tennessine']) \n",
      "\n",
      "\n",
      "Properties: ['symbol', 'atomic_number', 'atomic_mass', 'electronegativity']\n",
      "\n",
      "The atomic mass of Chlorine is 35.45 amu.\n"
     ]
    }
   ],
   "source": [
    "print(halogen_dict.keys(),\"\\n\")\n",
    "for element, properties in halogen_dict.items():\n",
    "    # Print the element symbol (key of the outer dictionary)\n",
    " #   print(f\"Element: {element}\")\n",
    "\n",
    "    # Since all inner dictionaries have the same keys, we can break after the first iteration\n",
    "    break\n",
    "\n",
    "print(\"\\nProperties:\", list(properties.keys()))\n",
    "print(f\"\\nThe atomic mass of Chlorine is {halogen_dict['Chlorine']['atomic_mass']} amu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814146a-f9fb-4f52-a1e6-7461a96b6331",
   "metadata": {},
   "source": [
    "# Pickle Files (.pkl, Python Object Serialization)\n",
    "- Can store **any Python object** (dictionaries, lists, NumPy arrays, custom objects).\n",
    "- Faster and more space-efficient than JSON (because it‚Äôs binary).\n",
    "- Not human-readable and not cross-language compatible.\n",
    "- Security risk: Do not load a Pickle file from an untrusted source, it could execute malicious code.\n",
    "- Great for saving Python-specific data efficiently (e.g., Pandas DataFrames, machine learning models).\n",
    "- Not a universal format (not for data sharing).\n",
    "- Only use Pickle when working within Python projects.\n",
    "- **Pickle does not preserve variable names**, pickle a dictionary to preserve names\n",
    "\n",
    "When you unpickle a list of objects, the original variable names are not preserved. The pickle module only serializes the object data, not the variable names used to refer to those objects. Therefore, there's no direct way to retrieve the original variable names from the unpickled list.\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `dump(obj, file)` | Write a pickled representation of obj to the open file object |\n",
    "| `dumps(obj)` | Return the pickled representation of the object as a bytes object |\n",
    "| `load(file)` | Read a pickled object from the open file object |\n",
    "| `loads(bytes_object)` | Read a pickled object from a bytes object |\n",
    "\n",
    "In summary, while you don't need to manually reimport modules when unpickling, you do need to ensure that the required modules are available and compatible in the unpickling environment. The pickle module handles the import process automatically, but it doesn't package the entire module content with the pickled object.\n",
    "\n",
    "## Using a Dictionary to Preserve Names\n",
    "When you unpickle a list of objects, the original variable names are not preserved. The pickle module only serializes the object data, not the variable names used to refer to those objects. Therefore, there's no direct way to retrieve the original variable names from the unpickled list.\n",
    "\n",
    "However, you can achieve a similar result by using a dictionary instead of a list when pickling your objects. This way, you can associate each object with a meaningful key that represents its name. Here's how you can modify your code to accomplish this:\n",
    "\n",
    "\n",
    "## Pickle the Dictionary\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# Define the Pickle file path\n",
    "pickle_file_path = os.path.expanduser(\"~/filepath/filename.pkl\")\n",
    "\n",
    "# Save the dictionary as a Pickle file\n",
    "with open(halogen_pkl_sbpath, \"wb\") as pickle_file:\n",
    "    pickle.dump(pickle_file_path, pickle_file)\n",
    "\n",
    "print(f\"Periodic table data pickled at: {pickle_file_path}\"))\n",
    "```\n",
    "\n",
    "## Unpickle and Reload Later\n",
    "```python\n",
    "# Load the Pickle file\n",
    "with open(pickle_file_path, \"rb\") as pickle_file:\n",
    "    unpickled_file = pickle.load(pickle_file)\n",
    "```\n",
    "See code below for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c518fc4-a058-4091-b590-d3e0076d1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fluorine': {'symbol': 'F', 'atomic_number': 9, 'atomic_mass': 18.998, 'electronegativity': 3.98}, 'Chlorine': {'symbol': 'Cl', 'atomic_number': 17, 'atomic_mass': 35.45, 'electronegativity': 3.16}, 'Bromine': {'symbol': 'Br', 'atomic_number': 35, 'atomic_mass': 79.904, 'electronegativity': 2.96}, 'Iodine': {'symbol': 'I', 'atomic_number': 53, 'atomic_mass': 126.9, 'electronegativity': 2.66}, 'Astatine': {'symbol': 'At', 'atomic_number': 85, 'atomic_mass': 210.0, 'electronegativity': 2.2}, 'Tennessine': {'symbol': 'Ts', 'atomic_number': 117, 'atomic_mass': 294.0, 'electronegativity': None}} \n",
      "\n",
      "Periodic table data pickled at: /home/rebelford/sandbox/halogen.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Define paths in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_pkl_sbpath = os.path.join(sandbox_dir, \"halogen.pkl\")\n",
    "halogen_json_sbpath = os.path.join(sandbox_dir, \"halogens.json\")\n",
    "\n",
    "# Open the dictionary\n",
    "with open(halogen_json_sbpath, \"r\") as file:\n",
    "    halogen_dict = json.load(file)\n",
    "    print(halogen_dict,'\\n')\n",
    "\n",
    "\n",
    "# Define pickle path in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_pkl_sbpath = os.path.join(sandbox_dir, \"halogen.pkl\")\n",
    "\n",
    "# Save the dictionary as a Pickle file\n",
    "with open(halogen_pkl_sbpath, \"wb\") as pickle_file:\n",
    "    pickle.dump(halogen_dict, pickle_file)\n",
    "\n",
    "print(f\"Periodic table data pickled at: {halogen_pkl_sbpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5bccbe-e1bb-4a67-a542-d95df441d87e",
   "metadata": {},
   "source": [
    "## Unpickle file\n",
    "Now that you have pickled the file, let's unpickle it, but first **restart kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09d54f26-4b10-475d-8775-5e04f8da9fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fluorine': {'symbol': 'F', 'atomic_number': 9, 'atomic_mass': 18.998, 'electronegativity': 3.98}, 'Chlorine': {'symbol': 'Cl', 'atomic_number': 17, 'atomic_mass': 35.45, 'electronegativity': 3.16}, 'Bromine': {'symbol': 'Br', 'atomic_number': 35, 'atomic_mass': 79.904, 'electronegativity': 2.96}, 'Iodine': {'symbol': 'I', 'atomic_number': 53, 'atomic_mass': 126.9, 'electronegativity': 2.66}, 'Astatine': {'symbol': 'At', 'atomic_number': 85, 'atomic_mass': 210.0, 'electronegativity': 2.2}, 'Tennessine': {'symbol': 'Ts', 'atomic_number': 117, 'atomic_mass': 294.0, 'electronegativity': None}}\n",
      "\n",
      "Data for Oxygen (from Pickle):\n",
      "Element not found!\n",
      "\n",
      "Data for chlorine (from Pickle):\n",
      "{'symbol': 'Cl', 'atomic_number': 17, 'atomic_mass': 35.45, 'electronegativity': 3.16}\n",
      "\n",
      "Electronegativity data for chlorine (from Pickle):\n",
      "3.16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define path in ~/sandbox/\n",
    "sandbox_dir = os.path.expanduser(\"~/sandbox/\")\n",
    "halogen_pkl_sbpath = os.path.join(sandbox_dir, \"halogen.pkl\")\n",
    "\n",
    "# Load the Pickle file\n",
    "with open(halogen_pkl_sbpath, \"rb\") as pickle_file:\n",
    "    unpickled_halogens = pickle.load(pickle_file)\n",
    "\n",
    "# Display a sample element (Oxygen)\n",
    "print(unpickled_halogens)\n",
    "print(f\"\\nData for Oxygen (from Pickle):\")\n",
    "print(unpickled_halogens.get(\"Oxygen\", \"Element not found!\"))\n",
    "print(f\"\\nData for chlorine (from Pickle):\")\n",
    "print(unpickled_halogens.get(\"Chlorine\", \"Element not found!\"))\n",
    "print(f\"\\nElectronegativity data for chlorine (from Pickle):\")\n",
    "print(unpickled_halogens['Chlorine']['electronegativity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b38e66-90c7-4ed4-aebd-44a98dca5884",
   "metadata": {},
   "source": [
    "# Download csv file from PubChem Periodic Table\n",
    "\n",
    "## Code to download table\n",
    "The following code will create a data directory in your class directory within your home directory where we will keep real data files this semester.  It then creates a subdirectory called pubchem_data_dir, where we will keep files dealing with PubChem. Inside of it we will download a csv file of 17 different properties of the periodic table.  To do this we will use the requests module that will be discussed in the next session, and the pandas package that we will be using in the near future.  \n",
    "If you navigate to [PubChem Periodic Table](https://pubchem.ncbi.nlm.nih.gov/periodic-table/) you will see a download tab that takes you to a series of Machine-Readable Periodic Table Data files. You can obtain the link to the csv file in the code cell below by right-clicking onthe CSV-Save file, and choosing 'copy link address', which we have assigned to the variable \"file_url\".\n",
    "\n",
    "If you have not installed pandas you need to do so now.\n",
    "### Install Pandas\n",
    "Pandas is a very powerful data science package that we will be using extensively as soon as we finish this primer tutorial on Python. If you have not already installed it in your class environment, \n",
    "**In the Ubuntu terminal activate your virtual environment (py4sci)**, changing py4sci to the nae of your environment\n",
    "```bash\n",
    "conda activate py4sci\n",
    "conda install -c conda-forge pandas\n",
    "```\n",
    "\n",
    "We will then use Pandas to print the first 5 lines of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64deddf2-0ef5-4942-bf33-487becb5e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PubChem CSV to: /home/rebelford/data/pubchem_data/PubChemElements_all.csv ...\n",
      "Download complete!\n",
      "File successfully saved at: /home/rebelford/data/pubchem_data/PubChemElements_all.csv\n",
      "\n",
      "First few rows of the dataset:\n",
      "   AtomicNumber Symbol       Name  AtomicMass CPKHexColor  \\\n",
      "0             1      H   Hydrogen    1.008000      FFFFFF   \n",
      "1             2     He     Helium    4.002600      D9FFFF   \n",
      "2             3     Li    Lithium    7.000000      CC80FF   \n",
      "3             4     Be  Beryllium    9.012183      C2FF00   \n",
      "4             5      B      Boron   10.810000      FFB5B5   \n",
      "\n",
      "  ElectronConfiguration  Electronegativity  AtomicRadius  IonizationEnergy  \\\n",
      "0                   1s1               2.20         120.0            13.598   \n",
      "1                   1s2                NaN         140.0            24.587   \n",
      "2               [He]2s1               0.98         182.0             5.392   \n",
      "3               [He]2s2               1.57         153.0             9.323   \n",
      "4           [He]2s2 2p1               2.04         192.0             8.298   \n",
      "\n",
      "   ElectronAffinity OxidationStates StandardState  MeltingPoint  BoilingPoint  \\\n",
      "0             0.754          +1, -1           Gas         13.81         20.28   \n",
      "1               NaN               0           Gas          0.95          4.22   \n",
      "2             0.618              +1         Solid        453.65       1615.00   \n",
      "3               NaN              +2         Solid       1560.00       2744.00   \n",
      "4             0.277              +3         Solid       2348.00       4273.00   \n",
      "\n",
      "    Density            GroupBlock YearDiscovered  \n",
      "0  0.000090              Nonmetal           1766  \n",
      "1  0.000179             Noble gas           1868  \n",
      "2  0.534000          Alkali metal           1817  \n",
      "3  1.850000  Alkaline earth metal           1798  \n",
      "4  2.370000             Metalloid           1808  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory structure\n",
    "base_data_dir = os.path.expanduser(\"~/data\")  # Parent directory\n",
    "pubchem_data_dir = os.path.join(base_data_dir, \"pubchem_data\")  # Subdirectory for PubChem\n",
    "os.makedirs(pubchem_data_dir, exist_ok=True)  # Ensure directories exist\n",
    "\n",
    "# Define file URL and local path\n",
    "file_url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/periodictable/CSV?response_type=save&response_basename=PubChemElements_all\"\n",
    "local_file_path = os.path.join(pubchem_data_dir, \"PubChemElements_all.csv\")\n",
    "\n",
    "# Download the file\n",
    "print(f\"Downloading PubChem CSV to: {local_file_path} ...\")\n",
    "urllib.request.urlretrieve(file_url, local_file_path)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "# Verify if the file was saved\n",
    "if os.path.exists(local_file_path):\n",
    "    print(f\"File successfully saved at: {local_file_path}\")\n",
    "\n",
    "    # Load into Pandas DataFrame\n",
    "    df = pd.read_csv(local_file_path)\n",
    "    print(\"\\nFirst few rows of the dataset:\")\n",
    "    print(df.head())  # Display first few rows\n",
    "\n",
    "else:\n",
    "    print(\"Download failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d0b70-e6d4-4b70-93ed-18b2810bbc54",
   "metadata": {},
   "source": [
    "# Assignment: \n",
    "Open the Workbook 4, download the periodic table from PubChem and then make yourself a data dictionary like you did above for four properties of the halogens, but now do it for the entire periodic table with the 17 properties in the csv file you just downloaded.  Once done, you should save it as a Json file, that you will upload to your class google drive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f663f1-964f-448c-bff7-a981684e41d4",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "This content was developed with assistance from [Perplexity AI](https://www.perplexity.ai/) and [Chat GPT](https://chatgpt.com/). Multiple queries were made during the Fall 2024 and the Spring 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9803b6d-4870-426b-8e02-b72418ef79e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py4sci)",
   "language": "python",
   "name": "py4sci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
