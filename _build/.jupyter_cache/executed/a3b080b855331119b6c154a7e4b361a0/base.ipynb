{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3891d4a-3023-44d6-a2f1-1a216e0acaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to: /home/rebelford/data/wikipedia/carbon_data.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime  # <- make sure this is at the top of your script\n",
    "\n",
    "# Define the directory and file path\n",
    "wikipedia_dir = os.path.expanduser(\"~/data/wikipedia/\")\n",
    "os.makedirs(wikipedia_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "carbon_wikipedia_path = os.path.join(wikipedia_dir, \"carbon_data.json\")\n",
    "\n",
    "def scrape_infobox(element_name):\n",
    "    \"\"\"Scrapes the Wikipedia infobox for a given element and returns a dictionary of properties.\"\"\"\n",
    "    \n",
    "    url = f\"https://en.wikipedia.org/wiki/{element_name}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the Infobox element\n",
    "    infobox = soup.find('table', class_='infobox')\n",
    "\n",
    "    # Dictionary to store element properties\n",
    "    element_data = {}\n",
    "\n",
    "\n",
    "    # Loop through table rows and extract key-value pairs\n",
    "    for row in infobox.find_all('tr'):\n",
    "        header = row.find('th')\n",
    "        value = row.find('td')\n",
    "\n",
    "        if header and value:\n",
    "            key = header.get_text(strip=True)  # Get property name\n",
    "            val = value.get_text(\" \", strip=True)  # Extract value, keeping spaces\n",
    "            element_data[key] = val\n",
    "\n",
    "    # Add provenance metadata\n",
    "    element_data[\"_source\"] = {\n",
    "        \"Wikipedia_URL\": url,\n",
    "        \"Scraped_from\": \"Wikipedia Infobox Element\",\n",
    "        #\"Scraped_on\": requests.get(\"https://worldtimeapi.org/api/timezone/Etc/UTC\").json()['datetime']\n",
    "        \"Scraped_on\": datetime.utcnow().isoformat() + \"Z\"\n",
    "    }\n",
    "\n",
    "    return {element_name: element_data}\n",
    "\n",
    "# Scrape data for Hydrogen\n",
    "carbon_data = scrape_infobox(\"Carbon\")\n",
    "\n",
    "# Save JSON data to file\n",
    "with open(carbon_wikipedia_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(carbon_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Data saved successfully to: {carbon_wikipedia_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd896f85-a9f4-43a0-8b4e-2ab3105de13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties available for Hydrogen:\n",
      "- Appearance\n",
      "- \n",
      "- Atomic number(Z)\n",
      "- Group\n",
      "- Period\n",
      "- Block\n",
      "- Electron configuration\n",
      "- Electrons per shell\n",
      "- PhaseatSTP\n",
      "- Melting point\n",
      "- Boiling point\n",
      "- Density(at STP)\n",
      "- when liquid (atm.p.)\n",
      "- when liquid (atb.p.)\n",
      "- Triple point\n",
      "- Critical point\n",
      "- Heat of fusion\n",
      "- Heat of vaporization\n",
      "- Molar heat capacity\n",
      "- P(Pa)\n",
      "- atT(K)\n",
      "- Oxidation states\n",
      "- Electronegativity\n",
      "- Ionization energies\n",
      "- Covalent radius\n",
      "- Van der Waals radius\n",
      "- Natural occurrence\n",
      "- Crystal structure\n",
      "- Lattice constants\n",
      "- Thermal conductivity\n",
      "- Magnetic ordering\n",
      "- Molar magnetic susceptibility\n",
      "- Speed of sound\n",
      "- CAS Number\n",
      "- Discoveryand first isolation\n",
      "- Named by\n",
      "- Recognized as anelementby\n",
      "- Main isotopes\n",
      "- 1H\n",
      "- 2H\n",
      "- 3H\n",
      "- _source\n",
      "\n",
      "\n",
      "Named by: Property not found\n",
      "(Source: https://en.wikipedia.org/wiki/Hydrogen)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define file path\n",
    "wikipedia_dir = os.path.expanduser(\"~/data/wikipedia/\")\n",
    "hydrogen_wikipedia_path = os.path.join(wikipedia_dir, \"hydrogen_data.json\")\n",
    "\n",
    "# Load the JSON file\n",
    "with open(hydrogen_wikipedia_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    hydrogen_data = json.load(f)\n",
    "\n",
    "# Extract Hydrogen properties\n",
    "hydrogen_properties = hydrogen_data.get(\"Hydrogen\", {})\n",
    "\n",
    "# Print all keys (property names)\n",
    "print(\"Properties available for Hydrogen:\")\n",
    "for key in hydrogen_properties.keys():\n",
    "    print(\"-\", key)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Print value for a specific key (\"Named by\") with provenance\n",
    "key_to_lookup = \"Named by\"\n",
    "value = hydrogen_properties.get(key_to_lookup, \"Property not found\")\n",
    "\n",
    "source_url = hydrogen_properties.get(\"_source\", {}).get(\"Wikipedia_URL\", \"Unknown Source\")\n",
    "\n",
    "print(f\"{key_to_lookup}: {value}\")\n",
    "print(f\"(Source: {source_url})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e8c680-5e39-4d77-88f2-22fea6b943e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to: /home/rebelford/data/wikipedia/halogens_data.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Define the list of halogens (either names or symbols)\n",
    "halogens = [\"Fluorine\", \"Chlorine\", \"Bromine\", \"Iodine\", \"Astatine\"]\n",
    "\n",
    "# Define file path for saving the scraped data\n",
    "wikipedia_dir = os.path.expanduser(\"~/data/wikipedia/\")\n",
    "os.makedirs(wikipedia_dir, exist_ok=True)  # Ensure directory exists\n",
    "halogens_wikipedia_path = os.path.join(wikipedia_dir, \"halogens_data.json\")\n",
    "\n",
    "\n",
    "def scrape_infobox(element_name):\n",
    "    \"\"\"Scrapes the Wikipedia infobox for a given element and returns a dictionary of properties.\"\"\"\n",
    "    \n",
    "    url = f\"https://en.wikipedia.org/wiki/{element_name}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the Infobox element\n",
    "    infobox = soup.find('table', class_='infobox')\n",
    "\n",
    "    # Dictionary to store element properties\n",
    "    element_data = {}\n",
    "   \n",
    "\n",
    "    # Loop through table rows and extract key-value pairs\n",
    "    for row in infobox.find_all('tr'):\n",
    "        header = row.find('th')\n",
    "        value = row.find('td')\n",
    "\n",
    "        if header and value:\n",
    "            key = header.get_text(strip=True)  # Get property name\n",
    "            val = value.get_text(\" \", strip=True)  # Extract value, preserving spaces\n",
    "            element_data[key] = val\n",
    "\n",
    "    # Add provenance metadata\n",
    "    element_data[\"_source\"] = {\n",
    "        \"Wikipedia_URL\": url,\n",
    "        \"Scraped_from\": \"Wikipedia Infobox Element\",\n",
    "        \"Scraped_on\": datetime.now(timezone.utc).isoformat()  # UTC time with explicit timezone\n",
    "    }\n",
    "  \n",
    "    return {element_name: element_data}\n",
    "\n",
    "\n",
    "# Create dictionary of dictionaries for all halogens\n",
    "halogens_data = {}\n",
    "\n",
    "for element in halogens:\n",
    "    halogens_data.update(scrape_infobox(element))\n",
    "\n",
    "# Save JSON data to file\n",
    "with open(halogens_wikipedia_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(halogens_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Data saved successfully to: {halogens_wikipedia_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [webscrape]",
   "language": "python",
   "name": "webscrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}